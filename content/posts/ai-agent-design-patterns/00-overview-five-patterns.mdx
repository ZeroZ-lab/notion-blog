---
title: AI Agent的五种设计模式
description: ''
date: '2025-02-20'
category: AI Agent
tags: []
published: true
cover: /images/posts/ai-agent的五种设计模式/cover.jpg
---


# **引言：开启智能的全新时代**


人工智能 (AI) 正以前所未有的速度改变着我们的世界。从机器学习到深度学习，AI 技术不断突破边界，为各行各业带来创新和效率提升。而现在，我们正站在 AI 发展的新前沿：Agentic AI。


那么，什么是 Agentic AI 呢？简单来说，Agentic AI 是一种更高级的 AI 形式，它不再是被动地执行指令，而是能够像人类一样进行**推理、规划、决策和行动**，自主地解决复杂的、多步骤的问题。 英伟达 (NVIDIA) 的博客将其定义为 AI 的下一个前沿，强调其通过复杂的推理和迭代规划自主解决复杂问题的能力 [^1]。 这种自主性是 Agentic AI 与传统 AI 的核心区别之一。


与传统的、确定性的 AI 系统（例如机器人流程自动化 (RPA)）不同，Agentic AI 是一种**概率性技术**，能够高度适应不断变化的环境和事件。UiPath 指出，Agentic AI 依靠模式和可能性来做出决策和采取行动 [^2]。 这种适应性使得 Agentic AI 能够更好地应对现实世界中的不确定性和复杂性。


正如 Medium 上的 Edwin Lisowski 所说，Agentic AI 专注于**自主性**，使其能够独立做出决策、采取行动和学习，以实现特定目标，从而充当虚拟助手 [^3]。 这种目标导向的特性使得 Agentic AI 能够专注于解决特定问题，并不断优化其行动策略以达成目标。


Endava 进一步将 Agentic AI 描述为 AI 的一个强大的进化，它使组织能够更自主地运营。它使用包括生成式 AI (GenAI) 在内的高级 AI 形式，作为具有角色 (persona) 的智能体，这些智能体从数据中学习并随着时间的推移进行调整 [^4]。 Aisera 也强调了 Agentic AI 的 **主动性**， 认为它是一个能够自主采取行动、实时适应并基于上下文和目标解决多步骤问题的高级 AI 系统，建立在利用大型语言模型（LLM）的多个 AI 智能体之上 [^5]。


# **Agentic AI 的核心要素：智能体、环境、目标、行动**


Agentic AI 的核心在于“智能体 (Agent)”。 我们可以将智能体看作是一个能够**感知环境、进行推理、做出决策并采取行动**的实体。


每个智能体都拥有：

- **感知能力：** 能够接收和理解来自环境的信息，例如：传感器数据、用户输入、网络信息等。
- **推理能力：** 能够根据已知信息进行逻辑推理和判断，例如：使用知识图谱、规则引擎、机器学习模型等。
- **决策能力：** 能够根据目标和环境状态选择合适的行动，例如：使用强化学习、规划算法、优化模型等。
- **行动能力：** 能够执行选定的行动，并对环境产生影响，例如：控制机器人、发送指令、生成文本等。

这些智能体存在于一个特定的**环境**中，这个环境可以是物理世界（例如：工厂、城市）、虚拟世界（例如：游戏、模拟器），甚至是社会环境（例如：社交网络、金融市场）。环境的复杂性和可预测性直接影响智能体的设计和性能。


```plain text
[ 🌍 环境 ]
  /   |   \\
/    |    \\
真实  虚拟  社会
```


智能体的目标是在这个环境中实现其设定的**目标**，例如：完成一项任务、最大化收益、最小化风险等。目标可以是明确的、量化的，也可以是模糊的、定性的。智能体的所有行动都旨在尽可能接近或实现其目标状态。


而实现目标的方式就是通过采取一系列的**行动**。行动的选择取决于智能体的推理能力、环境的状态和目标的性质。 智能体需要不断学习和调整自己的行动策略，以适应环境的变化并更好地实现目标。


# **Agentic AI 的价值与应用：赋能千行百业**


Agentic AI 拥有巨大的潜力，可以赋能各行各业，以下是一些具体的应用案例：

- **自动化客户服务：** Agentic AI 可以构建智能客服机器人，能够理解客户的需求，自主解决问题，并提供个性化的服务。例如，Aisera 提供的 Agentic AI 解决方案可以自动处理客户咨询、解决技术问题，并提供 24/7 全天候服务 [^5]。
- **智能推荐系统：** Agentic AI 可以分析用户的行为和偏好，主动推荐用户可能感兴趣的产品或服务。例如，Netflix 和 Amazon 使用 Agentic AI 来个性化推荐内容，提高用户满意度和转化率。
- **自动驾驶汽车：** Agentic AI 可以控制汽车的行驶，根据路况和交通规则做出决策，实现安全可靠的自动驾驶。例如，Tesla 和 Waymo 使用 Agentic AI 来实现车辆的感知、规划和控制。
- **供应链管理：** Agentic AI 可以优化供应链的各个环节，例如：预测需求、优化库存、调度物流，提高效率和降低成本。
- **金融交易：** Agentic AI 可以分析市场数据，自动进行交易决策，提高投资回报率和降低风险。

然而，Agentic AI 在带来巨大价值的同时，也面临着一些挑战：

- **可解释性：** Agentic AI 的决策过程可能非常复杂，难以理解和解释，这给监管和信任带来了挑战。
- **安全性：** Agentic AI 系统可能存在漏洞，容易受到攻击，导致数据泄露和系统崩溃。
- **伦理道德：** Agentic AI 的应用可能引发一些伦理道德问题，例如：隐私侵犯、算法歧视和就业替代。

# **设计模式的重要性：构建可靠且可维护的 Agentic AI 系统**


随着 Agentic AI 系统的日益复杂，如何构建可靠且可维护的系统成为了一个关键问题。设计模式为我们提供了一种有效的解决方案。


设计模式是软件工程中经过验证的、可重用的解决方案，用于解决常见的设计问题。 它们就像建筑蓝图一样，可以帮助我们更好地组织和构建代码，提高代码的可读性、可维护性和可扩展性。


```plain text
🧱 设计模式 🧱
/   |   \\
重用 可靠 维护
```


在 Agentic AI 领域，设计模式可以帮助我们：

- **降低系统复杂性：** 通过将系统分解为模块化的组件，简化设计和开发过程。
- **提高代码重用性：** 通过使用通用的解决方案，减少重复代码的编写，提高开发效率。
- **增强系统可维护性：** 通过采用清晰的设计模式，方便代码的理解和修改，降低维护成本。
- **促进团队协作：** 通过使用统一的设计模式，提高团队成员之间的沟通效率，减少协作成本。

本系列文章将重点介绍五种常见的 Agentic AI 设计模式，它们分别是：

- **反思模式 (Reflection Pattern):** 智能体通过自我审查和迭代改进输出质量。
- **工具使用模式 (Tool Use Pattern):** 智能体利用外部工具和 API 扩展能力。
- **ReAct 模式 (ReAct Pattern):** 智能体结合推理和行动，动态适应环境。
- **规划模式 (Planning Pattern):** 智能体将复杂任务分解为子任务，并规划执行顺序。
- **多智能体模式 (Multi-Agent Pattern):** 多个智能体协同工作，共同完成目标。

# **总结与展望：拥抱 Agentic AI 的未来**


Agentic AI 代表着 AI 发展的一个重要方向。它不仅能够提高效率、降低成本，还能够创造新的价值和机会。然而，Agentic AI 也面临着一些挑战，需要我们认真对待和解决。


通过学习和应用 Agentic AI 设计模式，我们可以构建更加可靠、可维护和可扩展的 Agentic AI 系统， 从而更好地利用 Agentic AI 的潜力，为人类社会带来更大的福祉。


## 反思模式：打造自省的智能体 - AI 如何像人类一样自我提升？

## **引言：AI 也需要“照镜子”，才能变得更好**


想象一下，你在写一封重要的邮件，发给你的老板或者客户。你会草草写完就发送吗？当然不会！你会仔细检查每一个字、每一个标点符号，确保邮件内容清晰、措辞得当，甚至会请同事帮忙审阅，力求万无一失。 这种“回头看、找不足、再改进”的过程，就是一种反思。


在人工智能 (AI) 的世界里，也有一种类似的反思机制，它被称为“反思模式 (Reflection Pattern)”。 这是一种让 AI 系统能够自我评估、发现问题并不断改进的技术。 就像我们人类需要“照镜子”才能看到自己的不足一样，AI 也需要反思模式才能变得更加智能和可靠。


```plain text
( ಠ ಠ )  人 类
    |       写邮件
   👓     反思、修改
    |
  👍     完美邮件！
```


那么，这种神奇的反思模式到底是什么？它又是如何工作的呢？ 让我们一起揭开它的神秘面纱！


### Agentic AI 的“超能力”：自主思考和行动


要理解反思模式，我们首先要了解 Agentic AI。 简单来说，Agentic AI 是一种具有“超能力”的 AI，它不再是被动地听从指令，而是能够像一个智能助手一样，自主思考、制定计划并采取行动来解决问题。 想象一下钢铁侠的贾维斯，或者《星际迷航》里的电脑，它们都可以根据指令自主行动，甚至在没有明确指令的情况下也能主动提供帮助。


```plain text
🤖 Agentic AI 🤖
/ | \\
自主思考  制定计划  采取行动
```


这种“超能力”让 Agentic AI 在各行各业都有着广泛的应用前景，例如：

- 智能客服：能够理解用户的问题，并主动提供解决方案，而不仅仅是按照预设的流程回答。
- 自动驾驶：能够根据复杂路况自主规划行驶路线，并安全驾驶，即使遇到突发情况也能做出正确的决策。
- 内容创作：能够自主撰写文章、生成代码，甚至创作音乐，为人类提供源源不断的创意灵感。

然而，就像人类一样，Agentic AI 在解决问题的过程中也难免会犯错。 比如，它可能会生成不准确的信息、带有偏见的观点，或者不符合安全规范的内容。 这时候，就需要反思模式来“纠正错误”，让 AI 变得更加完美。


### 反思模式：让 AI 拥有“第二次机会”


反思模式的核心思想是：**让 AI 系统能够像人类一样，对自己的输出进行评估、反思，并根据反思结果进行改进。** 这样，即使 AI 在第一次尝试中犯了错，它也有机会通过反思来纠正错误，并不断提高自己的能力。


反思模式就像一个循环，包含三个关键步骤：

1. **生成：** AI 系统生成初始输出，比如一篇文章、一段代码或一张图片。 可以想象成 AI 第一次“尝试”解决问题。
2. **评估：** AI 系统对自己的输出进行评估，判断其质量、准确性、可靠性和安全性。 就像我们检查自己的作业一样，AI 也要评估自己的成果是否合格。
3. **改进：** 根据评估结果，AI 系统对初始输出进行修改和优化，力求让输出更加完美。 这就像我们根据老师的批改意见修改作业一样，AI 也要根据评估结果改进自己的输出。

```plain text
🔄 反思模式 🔄
 生成 --> 评估 --> 改进
    ^          |
    |__________|
```


这个循环会不断重复，直到 AI 系统生成令人满意的输出为止。 我们可以把这个过程想象成一个雕刻家不断雕琢作品的过程，每一次雕琢都让作品更加完美。


### AI 如何“自我评估”？不同的“照镜子”方法


在反思模式中，“评估”是一个非常重要的环节。 那么，AI 又是如何“自我评估”的呢？ 其实，AI 可以使用不同的方法来“照镜子”， 常见的有以下几种：

- **基于规则的评估：** 就像老师批改作业一样，AI 会根据预先设定的规则来检查自己的输出。 比如，检查文章是否有语法错误，代码是否符合编程规范等。 这种方法简单直接，但缺乏灵活性，就像只能用尺子测量长度，无法评估颜色和纹理。
- **基于模型的评估：** 训练一个专门的 AI 模型来评估输出的质量。 这种方法更加灵活，能够处理更复杂的情况，但需要大量的训练数据，就像训练一个专业的“评审团”来评估 AI 的作品。
- **基于数据的评估：** 将 AI 的输出与真实数据或标准答案进行比较，评估其准确性和可靠性。 这种方法能够更好地反映实际应用场景的需求，就像通过“考试”来检验 AI 的学习成果。

### RLAIF：让 AI 用 AI 来“指导”自己


最近，出现了一种新的反思模式，叫做 RLAIF (Reinforcement Learning from AI Feedback)， 也就是**用 AI 来“指导” AI**。 简单来说，就是用一个 AI 模型来评估另一个 AI 模型的输出，并根据评估结果进行改进。


这种方法的好处是：

- 更高效：AI 可以自动生成大量的反馈数据，无需人工干预，就像拥有了一个不知疲倦的“导师”。
- 更客观：AI 不会受到人类主观偏见的影响，能够更加客观地评估输出质量，就像拥有了一个公正的“裁判”。
- 更安全：可以使用一套预定义的原则来指导 AI 的反馈，确保输出的安全性和可靠性，就像为 AI 设置了一套“行为准则”。

```plain text
👨‍🏫 AI 导师 🤖
    |       反馈、指导
   ✅     RLAIF
    |
  🚀     AI 系统提升！
```


### 反思模式的“魔力”：让 AI 变得更强大


反思模式为 Agentic AI 带来了许多好处：

- 提高输出质量：通过不断地自我评估和改进，AI 能够生成更加准确、可靠和安全的内容。 就像一个工匠不断打磨自己的作品，最终呈现出完美的结果。
- 增强适应性：AI 能够适应新的信息和不断变化的环境，保持其有效性和相关性。 就像一个演员能够不断学习新的技能，适应不同的角色。
- 降低开发成本：反思模式可以减少人工干预，提高开发效率，降低开发成本，就像一个团队拥有了自动化的工具，能够更高效地完成任务。

然而，反思模式也并非完美无缺。 它需要消耗大量的计算资源，并且可能陷入局部最优解。 因此，我们需要不断探索新的方法，来提高反思模式的效率和效果。


### 代码示例：用 Python 实现简单的反思循环


```python
import openai

# 设置 OpenAI API 密钥
openai.api_key = "YOUR_OPENAI_API_KEY"

def generate_text(prompt):
  """使用 OpenAI API 生成文本"""
  response = openai.Completion.create(
      engine="text-davinci-003",  # 可以选择其他合适的引擎
      prompt=prompt,
      max_tokens=150,
      n=1,
      stop=None,
      temperature=0.7,
  )
  return response.choices[0].text.strip()

def evaluate_text(text):
  """简单评估文本质量（可以根据需要自定义评估规则）"""
  if "错误" in text or "不好" in text:
    return "文本质量较低，需要改进"
  else:
    return "文本质量较好"

def improve_text(text, feedback):
  """根据反馈改进文本"""
  if "需要改进" in feedback:
    prompt = f"请改进以下文本：\\n{text}\\n\\n改进后的文本："
    improved_text = generate_text(prompt)
    return improved_text
  else:
    return text

# 初始提示
initial_prompt = "请写一段关于人工智能的简短介绍"

# 生成初始文本
initial_text = generate_text(initial_prompt)
print(f"初始文本：\\n{initial_text}")

# 评估文本质量
feedback = evaluate_text(initial_text)
print(f"评估反馈：\\n{feedback}")

# 改进文本（如果需要）
improved_text = improve_text(initial_text, feedback)
if improved_text != initial_text:
  print(f"改进后的文本：\\n{improved_text}")
else:
  print("无需改进")
```


## **结语：让 AI 拥有自我进化的能力**


反思模式是 Agentic AI 走向成熟的关键一步。 它赋予 AI 自我进化的能力，让 AI 能够不断学习、成长，并更好地服务于人类社会。


```plain text
✨ 🤖 Agentic AI ✨
/ | \\
不断学习  自我进化  服务人类
```


## 工具使用模式：赋予智能体无限可能

## **引言：从石器到 API，工具是智能的延伸**


纵观人类文明的发展史，工具始终扮演着至关重要的角色。 从最初的石器，到精密的算盘，再到如今的计算机，工具不断扩展着人类的能力边界，加速着社会进步的步伐。 想象一下，如果没有工具，我们该如何建造房屋、耕种土地、探索宇宙？


在人工智能 (AI) 领域，也存在着一种类似的“工具”概念，它被称为“工具使用模式 (Tool Use Pattern)”。 这种模式赋予 Agentic AI 智能体调用外部资源、API 和专业工具的能力，使其能够突破自身预训练知识的局限，解决更加复杂的问题。


```plain text
🛠️  工具 = 力量 🚀
赋予 AI 无限可能
```


正如工具扩展了人类的能力一样，工具使用模式也极大地扩展了 Agentic AI 的能力。 那么，为什么 Agentic AI 需要工具使用模式？它又是如何工作的呢？ 让我们一起深入探索！


**Agentic AI 的“短板”：知识的边界**


Agentic AI 智能体，尤其是基于大型语言模型 (LLM) 的智能体，在自然语言理解、生成和推理方面表现出色。 然而，LLM 也存在着一些固有的局限性：

- 知识截止日期：LLM 的知识仅限于训练数据，无法获取最新的信息。
- 缺乏实时数据：LLM 无法直接访问实时数据，例如：天气信息、股票价格等。
- 无法执行特定操作：LLM 无法执行需要与外部系统交互的操作，例如：发送邮件、预订机票等。

这些局限性限制了 Agentic AI 的应用范围，使其难以处理需要实时信息、复杂计算或特定领域专业知识的任务。


**工具使用模式：弥合知识鸿沟，释放无限潜能**


工具使用模式通过集成外部工具、API 和服务，弥补了 LLM 的这些不足。 智能体可以利用这些工具：

- 获取实时信息：使用搜索引擎 API 检索最新的新闻报道或天气信息。
- 执行复杂计算：使用数学计算库进行复杂的数学运算或统计分析。
- 访问特定领域知识库：使用医疗知识图谱查询疾病诊断和治疗方案。
- 自动化各种任务：使用 Zapier 或 IFTTT 自动化发送邮件、社交媒体发帖等任务。

```plain text
🌐 + 🧰 = 💡
互联网 + 工具 = 智能爆发
```


通过工具使用模式，Agentic AI 智能体不再局限于自身已有的知识，而是可以像人类一样，利用各种工具来扩展能力，解决更加复杂的问题。 这种能力极大地扩展了 Agentic AI 的应用范围，使其能够应用于更多领域。


**工具使用模式的核心机制：发现、选择、调用、整合**


工具使用模式并非简单地将工具堆砌在一起，而是需要精心设计和实现。 一个完整的工具使用模式通常包含以下四个核心机制：

- 工具发现 (Tool Discovery)：智能体如何找到合适的工具？
- 工具选择 (Tool Selection)：智能体如何选择最佳工具？
- 工具调用 (Tool Invocation)：智能体如何使用工具？
- 结果整合 (Result Integration)：智能体如何理解和使用工具的结果？

接下来，我们将逐一介绍这些核心机制。


## 1. 工具发现：大海捞针，智能定位


工具发现是指智能体根据任务需求，从海量的工具中找到合适的工具。 这就像在大海捞针一样，需要高效的搜索和筛选机制。


目前，常用的工具发现方法包括：

- **预定义工具列表：** 智能体预先配置了可用的工具及其描述，例如：工具名称、功能描述、API 文档链接。 这种方法适用于工具种类有限且相对稳定的环境。 比如，智能客服系统通常会配置知识库查询工具、订单查询工具、退款申请工具等。

```plain text
📜 预定义列表 📜
工具1:  功能描述 ...
工具2:  功能描述 ...
...
```

- **知识图谱：** 利用知识图谱构建工具之间的关系，帮助智能体根据任务需求找到相关工具。 这种方法适用于需要处理复杂关系和推理的任务。 比如，医疗诊断助手可以使用知识图谱查找与疾病相关的诊断工具和治疗方案。

```plain text
🧠 知识图谱 🧠
(疾病) --(诊断工具)--> (工具A)
(疾病) --(治疗方案)--> (工具B)
```

- **语义搜索：** 智能体使用自然语言描述任务需求，并通过语义搜索找到功能匹配的工具。 这种方法适用于工具种类繁多且描述信息丰富的环境。 比如，智能助手可以使用搜索引擎查找能够完成特定任务的 API。

```plain text
🔍 语义搜索 🔍
用户:  我需要一个翻译 API
引擎:  查找 "翻译 API" 相关工具
结果:  ...
```


### 2. 工具选择：精挑细选，量身定制


找到可用的工具后，智能体需要根据任务需求选择最佳工具。 这就像在百货商场购物一样，需要根据自己的需求和预算进行精挑细选。


智能体选择工具时，通常会考虑以下因素：

- **任务需求匹配：** 分析任务的具体需求，例如：输入数据类型、输出数据格式、所需功能等，并选择满足这些需求的工具。 为了实现更精确的匹配，可以使用机器学习模型进行辅助。
- **工具可用性：** 检查工具是否可用且正常运行，例如：检查 API 是否返回错误代码、服务器是否正常响应等。 可以使用监控系统实时监测工具的可用性，确保智能体能够及时发现并处理工具故障。
- **成本与性能：** 考虑使用工具的成本和预期的性能，例如：API 调用次数限制、响应时间、计算资源消耗等。 可以使用性能测试工具对工具进行评估，选择性价比最高的工具。

```plain text
✅ 工具选择 ✅
任务需求  |  可用性  |  成本/性能
---------|---------|---------
匹配度高  |   稳定   |   性价比高
```


### 3. 工具调用：连接世界，操控万物


选择好合适的工具后，智能体需要实际调用这些工具来完成任务。 这就像使用遥控器控制电视一样，需要建立连接并发送指令。


常用的工具调用方法包括：

- **API 调用：** 使用 HTTP 请求调用 REST API，并将任务相关的数据作为参数传递给 API。 这是最常见的工具调用方法，适用于大多数 Web 服务。 例如，使用 OpenWeatherMap API 获取天气信息。

```python
import requests

    API_KEY = "YOUR_OPENWEATHERMAP_API_KEY"
    CITY_NAME = "London"
    API_URL = f"<http://api.openweathermap.org/data/2.5/weather?q={CITY_NAME}&appid={API_KEY}&units=metric>"

    response = requests.get(API_URL)

    if response.status_code == 200:
        data = response.json()
        temperature = data["main"]["temp"]
        humidity = data["main"]["humidity"]
        description = data["weather"][0]["description"]

        print(f"天气：{CITY_NAME}")
        print(f"温度：{temperature}°C")
        print(f"湿度：{humidity}%")
        print(f"描述：{description}")
    else:
        print("获取天气信息失败")
```

- **代码库调用：** 调用本地或远程的代码库执行特定功能，例如：使用 Python 的 Pandas 库进行数据分析。 这种方法适用于需要进行复杂计算或数据处理的任务。
- **服务编排平台：** 利用 IFTTT 或 Zapier 等平台连接各种 Web 服务，并根据事件触发相应的操作。 这种方法适用于需要自动化各种任务的场景，例如：当收到新的邮件时，自动将其转发到 Slack 频道。

### 4. 结果整合：化繁为简，融会贯通


调用工具后，智能体需要理解和使用工具返回的结果。 这就像阅读一本厚厚的书一样，需要提取关键信息并将其整合到自己的知识体系中。


常用的结果整合方法包括：

- **结果解析：** 将工具返回的原始数据转换为智能体能够理解的格式，例如：将 JSON 数据解析为 Python 字典。
- **信息提取：** 从解析后的数据中提取与任务相关的信息，例如：从天气 API 返回的数据中提取温度和湿度。
- **知识更新：** 将提取的信息整合到智能体的知识库中，以便后续使用。

```plain text
📦 结果整合 📦
原始数据 --> 解析 --> 提取 --> 知识库
```


## **工具使用模式的优势与挑战：无限可能，风险并存**


工具使用模式为 Agentic AI 带来了诸多优势：

- 扩展智能体的能力范围：智能体可以利用各种工具完成超出自身能力范围的任务，例如：利用图像识别 API 分析图片内容，或者利用语音合成 API 将文本转换为语音。
- 获取实时信息：智能体可以利用新闻 API 获取最新的新闻报道，或者利用股票 API 获取实时的股票价格，从而做出更明智的决策。
- 利用专业工具：智能体可以利用数学计算库进行复杂的数学计算，或者利用化学信息学工具进行药物设计，从而提高任务完成的效率和质量。

```plain text
🎉 工具使用优势 🎉
能力扩展 | 实时信息 | 专业工具
```


然而，工具使用模式也面临着一些挑战：

- 工具可靠性：外部工具可能不稳定或出现故障，影响智能体的性能。
- 安全风险：调用外部 API 存在数据泄露或未授权访问的风险。
- 复杂性：集成多个工具到工作流程中可能非常复杂，需要仔细设计和测试。

```plain text
⚠️ 工具使用挑战 ⚠️
工具可靠性 | 安全风险 | 流程复杂
```


**应用案例：工具使用模式大显身手**


工具使用模式在各个领域都有着广泛的应用，以下是一些具体的案例：

- 信息检索：智能体使用搜索引擎 API 检索相关网页，并从网页中提取答案，从而回答用户提出的关于特定主题的问题。
- 数据分析：智能体使用 Python 和数据分析库显身手**

工具使用模式在各个领域都有着广泛的应用，以下是一些具体的案例：

- 信息检索：智能体使用搜索引擎 API 检索相关网页，并从网页中提取答案，从而回答用户提出的关于特定主题的问题。
- 数据分析：智能体使用 Python 和数据分析库处理和分析大量的用户数据，以识别用户行为模式和预测用户需求。
- 自动化任务：智能体使用 Zapier 或 IFTTT 等平台连接各种 Web 服务，自动执行一些重复性的任务，例如：发送邮件、社交媒体发帖等。
- 智能家居控制：智能体使用智能家居平台的 API 控制智能家居设备，例如：打开灯、调节温度、播放音乐等。

## **总结与展望：拥抱工具，赋能未来**


工具使用模式是 Agentic AI 走向成熟的关键一步。 它赋予 AI 智能体利用外部资源和专业工具的能力，极大地扩展了其应用范围，使其能够解决更加复杂的问题。


虽然工具使用模式面临着一些挑战，例如：工具可靠性、安全风险和复杂性，但这些挑战都可以通过技术手段来解决。 随着技术的不断发展，我们可以期待看到更智能的工具发现与选择机制、更安全的 API 调用方式、以及更易于使用的工具集成平台。


让我们拥抱工具，赋能 Agentic AI 的未来！


## ReAct 模式：打造动态适应环境的智能体

**引言：在变化的世界中，AI 如何随机应变？**


试想一下，你正在迷宫中探险。 前方的道路复杂多变，充满了未知和挑战。 你需要不断观察周围的环境，分析地图信息，并根据实际情况调整前进方向。 这种根据环境变化而随机应变的智慧，是人类在复杂环境中生存的关键。


在人工智能 (AI) 领域，也有一种类似的能力，它被称为 "ReAct 模式 (ReAct Pattern)"。 ReAct，顾名思义，即 "Reason + Act"，它是一种结合推理 (Reasoning) 和行动 (Acting) 的 Agentic AI 设计模式，赋予智能体动态适应环境的能力。


与只能按照预设程序执行任务的传统 AI 不同，ReAct 模式让智能体能够像人类一样，通过与环境互动，实时获取信息，并根据反馈调整自己的行为。 这种能力对于构建能够在真实世界中可靠运行的 AI 系统至关重要。


```plain text
(っ ͡° ͜ ʖ ͡°)っ ReAct 模式：让 AI 随机应变
```


那么，为什么 Agentic AI 需要 ReAct 模式？它又是如何工作的呢？ 让我们一起深入探索！


**Agentic AI 的“生存之道”：适应，而非预设**


在真实世界中，AI 系统面临着各种各样的挑战：

- 动态变化：环境 постоянно меняется，新的信息不断涌现。
- 不确定性：传感器数据可能存在噪声，预测模型可能存在误差。
- 复杂性：任务目标可能难以明确定义，行动路径可能千变万化。

传统的 AI 系统难以应对这些挑战，因为它们通常是基于预设规则或离线训练的模型，缺乏与环境的有效互动。 就像一个只会背诵地图的导航仪，一旦遇到道路封闭或交通拥堵，就会束手无策。


ReAct 模式通过让智能体能够与环境进行实时互动，克服了传统 AI 的这些局限性。 智能体可以：

- 观察环境：使用传感器或 API 获取最新的信息。
- 推理分析：使用 LLM 或其他推理引擎分析环境信息，识别当前状态，预测未来发展趋势。
- 行动决策：根据推理结果选择合适的行动，影响环境的状态。
- 循环反馈：不断重复观察、推理和行动的步骤，形成一个闭环反馈系统，直到达到目标。

```plain text
👁️ + 🧠 + ⚙️ = 💫 ReAct 循环：观察 + 推理 + 行动 = 动态适应
```


通过这种循环反馈机制，智能体能够不断学习和优化自己的行为策略，从而在复杂环境中实现长期目标。


**ReAct 模式的核心机制：三位一体，环环相扣**


ReAct 模式的核心机制可以概括为三个关键词：观察 (Observation)、推理 (Reasoning) 和行动 (Acting)。 这三个要素相互依存、相互促进，构成了一个完整的闭环反馈系统。


### 1. 观察：感知世界的“眼睛”


观察是指智能体通过各种传感器或 API 获取环境信息的过程。 这就像我们用眼睛观察周围的世界一样，是智能体进行后续推理和决策的基础。


```plain text
👁️ 观察 👁️
/   |   \\
传感器  API   数据
```


观察的具体实现方式取决于具体的应用场景。 常用的技术包括：

- 计算机视觉：用于处理图像和视频数据，例如：目标检测、场景识别等。 可以让智能体“看懂”周围的环境。
- 自然语言处理：用于处理文本数据，例如：情感分析、实体识别等。 可以让智能体“听懂”用户的指令。
- 语音识别：用于处理音频数据，例如：语音转文字、声纹识别等。 可以让智能体“理解”用户的语音。

为了让 LLM 能够有效利用观察结果，通常需要对原始数据进行预处理和格式化。


### 2. 推理：运筹帷幄的“大脑”


推理是指智能体使用 LLM 或其他推理引擎分析环境信息，识别当前状态、预测未来发展趋势，并制定行动计划的过程。 这就像我们用大脑思考问题一样，是智能体做出正确决策的关键。


```plain text
🧠 推理 🧠
/   |   \\
提示词  CoT  知识图谱
```


推理的具体实现方式取决于智能体的知识储备和任务目标。 常用的技术包括：

- Prompt Engineering：设计有效的提示词，引导 LLM进行正确的逻辑推论
- Chain-of-Thought (CoT)：逐步进行原因分析，提高决策结果的可解释性。
- 知识图谱：利用知识图谱进行知识推理和信息检索，快速找到决策依据。

为了提高推理的准确性和可靠性，需要控制 LLM 产生不真实结果，确保原因分析都有数据支持。


### 3. 行动：改变世界的“双手”


行动是指智能体根据行动计划执行相应的动作，影响环境的状态，这就像我们用双手改变周围的世界一样，是智能体实现目标的关键。


```plain text
⚙️ 行动 ⚙️
/   |   \\
API 调用  代码库  服务编排
```


行动的具体实现方式取决于智能体的类型和任务目标。常用的技术包括：

- API 调用：与外部服务进行交互，例如：控制机器人、发送邮件等。
- 代码库调用：执行本地或远程的代码，例如：数据分析、图像处理等。
- 服务编排平台：利用 IFTTT 或 Zapier 等平台连接各种 Web 服务，自动化工作流程。

为了保证行动的可靠性和安全性，需要对行动执行过程进行监控，并设计容错机制以应对突发情况。


**ReAct 模式的优势与挑战：智慧与挑战并存**


ReAct 模式为 Agentic AI 带来了诸多优势：

- 动态适应性：能够适应不断变化和不确定性的环境，提高鲁棒性。
- 自主决策能力：能够根据环境信息自主做出决策，无需人工干预，降低运营成本。
- 问题解决能力：能够通过与环境交互，逐步解决复杂的问题，实现长期目标。
- 可解释性：推理过程可见，方便调试和理解智能体的行为。

```plain text
✅ ReAct 优势 ✅
适应性 | 自主性 | 解决力 | 可解释
```


然而，ReAct 模式也面临着一些挑战：

- 环境建模：如何准确地对环境进行建模，捕捉关键特征，以便智能体进行有效推理和预测？
- 行动选择：如何在庞大的行动空间中选择最佳行动，平衡探索与利用，以实现目标？
- 稳定性：如何保证 ReAct 循环的稳定，避免震荡或陷入局部最优解？
- 幻觉问题：如何减轻 LLM 的幻觉对行动决策带来的负面影响，提高行动的可靠性？

```plain text
⚠️ ReAct 挑战 ⚠️
建模 | 选择 | 稳定性 | 幻觉
```


**应用案例：ReAct 模式在各行各业大显身手**


ReAct 模式在各个领域都有着广泛的应用，以下是一些具体的案例：

- **游戏 AI：** 游戏 AI 需要根据玩家的行为和游戏环境做出决策，以提供更具挑战性和趣味性的游戏体验。 使用 ReAct 模式控制游戏角色的行为，使其能够根据环境变化做出智能反应。
    - 例如：在一个射击游戏中，AI 控制的敌人可以根据玩家的位置、武器和行动，动态调整自己的战术，例如：移动到掩体后面、发起进攻或撤退。
- **机器人控制：** 机器人需要在复杂的环境中完成各种任务，例如：导航、抓取物体、避开障碍物等。 使用 ReAct 模式控制机器人的行动，使其能够适应环境变化并完成任务。
    - 例如：在一个仓库中，机器人需要自主拣货和搬运货物。 机器人可以使用摄像头观察周围的环境，使用 LLM 分析任务需求，并规划行动路线和抓取策略，最终将货物搬运到指定地点。
- **对话系统：** 对话系统需要根据用户的输入和对话历史生成合适的回复，以提供更自然和流畅的对话体验。 使用 ReAct 模式控制对话系统的行为，使其能够根据用户输入动态调整对话策略。
*   例如：一个智能客服系统需要理解用户意图、查询相关信息、并提供解决方案。 系统可以使用自然语言处理技术分析用户输入，使用知识图谱查询相关信息，并使用 LLM 生成合适的回复。
- **搜索代理：** 搜索代理需要在给定的网页信息中，更精准的寻找到正确答案，ReAct 模式可以控制搜索代理的搜索策略和信息提取过程。
    - 例如：Agent 利用工具来获取外部信息，然后决定下一步该怎么做，并不断重复这个过程，直到找到最终答案。

**代码示例：Python 实现简单的 ReAct 循环**


由于ReAct 模式的代码实现较为复杂，这里提供一个简化的伪代码示例，用于说明 ReAct 循环的基本流程：


```python
while True:
    # 1. 观察环境
    observation = observe_environment()

    # 2. 推理分析
    thought = reason(observation)

    # 3. 行动决策
    action = decide_action(thought)

    # 4. 执行行动
    result = execute_action(action)

    # 5. 更新环境信息
    update_environment(result)

    # 6. 判断是否达到目标或满足停止条件
    if is_goal_achieved() or is_stop_condition_met():
        break
```


请注意，这只是一个简化的示例，实际应用中需要根据具体场景进行调整和优化。


**总结与展望：ReAct，让 AI 拥有无限可能**


ReAct 模式是 Agentic AI 领域的一个重要突破。 它赋予 AI 智能体动态适应环境的能力，使其能够解决更加复杂的问题，并在各个领域都有着广泛的应用前景。


虽然 ReAct 模式面临着一些挑战，例如：环境建模、行动选择、稳定性和幻觉问题，但随着技术的不断发展，这些挑战都将迎刃而解。 我们可以期待看到更多基于 ReAct 模式的创新应用，为人类社会带来更大的福祉。


## 规划模式：赋予 Agentic AI 掌控全局的能力

好的，下面是在之前中文重写版本的基础上，使用 Markdown 增加标题样式的版本：


# **Agentic AI 设计模式系列（四）：规划模式**


这是 Agentic AI 设计模式系列的第四篇文章，我们将探讨 Agentic AI 的规划模式。在前两篇文章中，我们已经学习了智能体（Agent）如何进行反思（Reflection）和使用工具（Tool Use）来获取信息。在反思模式中，AI 智能体通过迭代生成和自我评估来提高输出质量。工具使用模式则使 AI 能够与外部系统、API 或资源进行交互，扩展其能力。


现在，我们来谈谈规划模式。想象一个智能助理，它不仅能反思并在需要时获取外部信息，还能决定解决更大问题的步骤顺序。很酷吧？更有趣的是：这个助理如何决定完成大型、多层次目标的最佳步骤顺序？有效的规划就是确定完成复杂、多步骤目标的结构化行动顺序。


## **规划模式提供了什么？**


规划模式为语言模型提供了将大型任务分解为可管理的子目标的策略，使它们能够逐步解决复杂的挑战，同时关注总体目标。本文将详细讨论规划模式，包括 ReAct 和 ReWOO 技术。


## **什么是 Agentic AI 规划模式？**


![image.png](/images/posts/AI-Agent的五种设计模式/image-1.png)


Agentic AI 规划模式是一个框架，专注于将大问题分解为较小的任务，有效地管理这些任务，并根据任务结果确保持续改进或适应。这个过程是迭代的，依赖于一个结构化的流程，以确保 AI 系统可以根据需要调整其计划，每次迭代都更接近期望的目标。


规划模式的主要组成部分：

1. **规划（Planning）：** 在初始阶段，AI 智能体解释提示并制定总体计划。该计划概述了 AI 打算如何解决问题，包括高级目标和策略。
2. **生成任务（Generate Task）：** 从计划中，AI 系统生成必须执行的特定任务。每个任务代表总体目标的一个较小、可管理的部分，使 AI 能够以集中的步骤工作。
3. **单一任务智能体（Single Task Agent）：** 单一任务智能体负责完成上一步生成的每个任务。该智能体使用预定义的方法（如 ReAct 或 ReWOO）执行每个任务。任务完成后，智能体返回一个任务结果（Task Result），该结果将被发送回规划循环。
4. **重新规划（Replan）：** 重新规划阶段评估任务结果，以确定是否需要进行任何调整。如果任务执行未完全满足预期结果，系统将重新规划并可能修改任务或策略。这个反馈循环使 AI 系统能够迭代学习和改进其方法，使其更能适应不断变化的需求或意外结果。
5. **迭代（Iterate）：** 模式的这一部分是连接“生成任务”和“重新规划”的循环。它表示该过程的迭代性质，其中 AI 系统不断重新评估和调整其方法，直到获得满意的结果。

Agentic AI 规划模式利用规划、任务生成、执行和重新规划的结构化循环，确保 AI 系统能够自主地朝着复杂目标努力。该模式通过允许 AI 根据任务结果修改其方法来支持适应性，使其对动态环境或不断变化的目标具有鲁棒性和响应性。


## **Agentic AI 规划模式示例**


![image.png](/images/posts/AI-Agent的五种设计模式/image-2.png)


上图描绘了一个顺序图像理解过程，其步骤与 Agentic AI 规划模式一致。在 Agentic AI 中，"智能体" 根据观察和计划的响应采取行动，以实现特定目标。下面是图像中的每个步骤如何适应 Agentic AI 框架：

1. **目标设定（理解任务）**
    - **提示：** 任务以一个问题开始：“你能描述这张图片并计算图片中有多少个物体吗？”
    - **Agentic AI 元素：** AI 智能体将此目标解释为分析图像以进行对象识别和描述的指令。目标是通过识别、计数和描述对象来全面回答问题。
2. **规划和子目标形成**
    - **过程分解：**
        - 为了完成这个目标，智能体将任务分解为特定的子任务：
            - 对象检测（识别和定位对象）
            - 分类（识别每个对象是什么）
            - 字幕生成（生成场景的自然语言描述）
    - **Agentic AI 元素：** 智能体通过在 Agentic AI 规划模式中设置中间子目标来规划其行动。在这里，检测对象是完成最终目标（生成包含对象计数的描述性字幕）所需的子目标。
3. **感知和行动（检测和描述）**
    - **使用的工具和模型：**
        - 智能体利用 `facebook/detr-resnet-101` 模型进行检测，该模型识别和定位对象（例如，长颈鹿和斑马）并分配置信度分数。
        - 检测后，智能体使用 `nlpconnect/vit-gpt2-image-captioning` 生成描述性字幕。
    - **Agentic AI 元素：** 智能体使用特定的感知模块（预训练模型）“感知”其环境（图像），这些模块允许它收集必要的信息。在 Agentic AI 中，感知是一个主动的、面向目标的过程。在这里，模型充当感知工具，处理视觉信息以实现总体目标。
4. **评估和迭代（合并结果）**
    - **处理和聚合信息：** 将检测结果（边界框和对象类型）和字幕生成结果（描述性文本）合并。智能体评估其输出，确认对象检测置信度水平和描述的连贯性。
    - **Agentic AI 元素：** Agentic AI 涉及根据反馈和信息聚合持续评估和调整响应。智能体审查其预测（检测分数和边界框），以确保它们与任务的要求一致。
5. **目标达成（答案呈现）**
    - **输出呈现：** 智能体最终提供一个答案，其中包括检测到的对象计数、具有置信度分数的已识别对象列表以及描述性字幕。
    - **Agentic AI 元素：** 智能体通过将其感知和规划结果综合成一个连贯的响应来完成目标。在 Agentic AI 中，此步骤是关于实现任务的总体目标并生成解决用户初始问题的输出。

## **Agentic AI 规划的任务分解**


![image.png](/images/posts/AI-Agent的五种设计模式/image-3.png)


有两种不同的 Agentic AI 规划任务分解方法，专门设计用于处理动态和可变现实环境中的复杂任务。鉴于尝试对复杂目标进行单步规划的局限性，分解为可管理的部分变得至关重要。这个过程类似于“分而治之”策略，涉及将复杂的
目标分解为更小、更易于实现的子目标。


以下是对每种方法的解释：


### **(a) 优先分解法 (Decomposition-First Approach)**

- **分解步骤：** 在这种方法中，LLM 智能体首先将主要目标完全分解为子目标（子目标 1、子目标 2、...、子目标 n），然后再启动子任务。此步骤在图中用 1 表示。
- **子计划步骤：** 分解任务后，智能体独立地为每个子目标创建子计划。这些子计划定义了实现每个子目标所需的具体行动。此规划过程在图中标记为 2。
- **顺序执行：** 每个子计划按顺序依次执行，按顺序完成每个子目标，直到完成主要目标。

本质上，优先分解法将分解和执行阶段分开：它在开始执行之前完成子目标的所有规划。这种方法在变化最小的稳定环境中可能有效。


### **(b) 交错法 (Interleaved Approach)**


交错法中，分解和执行以更交织的方式发生：

- **同时规划和执行：** LLM 智能体不是在采取行动之前完全分解任务，而是从部分分解开始（例如，从子目标 1 开始），并立即开始规划和执行与此子目标相关的行动。
- **自适应分解：** 在处理每个子目标时，可能会识别和规划新的子目标，随着智能体的进展进行调整。智能体继续循环分解、规划和执行，允许灵活地响应变化或意外的环境复杂性。
- **动态执行：** 这种方法更具适应性，并且对不断变化的环境做出响应，因为规划和执行是交错的。这允许智能体根据实时反馈进行调整，根据需要修改子目标或行动。

简而言之：

- **优先分解法：** 一种结构化的、逐步的方法，在执行任何操作之前规划所有子目标。适用于任务定义明确且在执行期间不太可能发生变化的环境。
- **交错法：** 一种灵活的、自适应的方法，其中规划和执行同时发生。这种方法非常适合需要实时反馈和调整的动态环境。

在复杂的 AI 规划中，选择哪种方法取决于环境和任务的可变性。优先分解法强调结构和预先规划，而交错法则优先考虑适应性和实时响应能力。


这两种方法都有其自身的优势，但在面对高度动态和不可预测的场景时，它们也会带来独特的挑战。为了应对这种复杂性，一个名为 ReAct（Reasoning and Acting，推理和行动）的新兴框架在 AI 研究中变得越来越受欢迎。ReAct 以一种使智能体能够批判性地思考其行动的方式综合推理和行动，根据即时反馈调整其策略。这个框架将结构化规划与实时调整相结合，使智能体能够做出更复杂的决策，并处理各种环境中的可变性。


## **什么是 ReAct？**


![image.png](/images/posts/AI-Agent的五种设计模式/image-4.png)


我们已经知道，LLM 在提供语言理解和决策方面表现出令人印象深刻的能力。然而，它们推理和行动的能力一直是分开研究的课题。本节将讨论 LLM 如何使用推理和行动规划，通过 ReAct 方法更好地协同处理复杂任务。以下是 ReAct（Reason + Act）框架在语言模型（LM）系统中的演变和意义。它对比了传统方法（仅推理和仅行动模型）与 ReAct（结合了推理和行动能力）。让我们分解 ReAct 架构的每个部分，以了解它所传达的内容。


### **ReAct 的工作流程**

1. **仅推理 (Reason Only)**
    - 这种模型只关注语言模型内的推理和思维过程。这种方法的一个例子是思维链（CoT）提示，其中语言模型通过逻辑步骤来解决问题，但不直接与环境交互。
    - 在这种仅推理模式下，模型生成一系列思想或“推理轨迹”，但无法采取行动或接收来自外部环境的反馈。它仅限于内部思考，没有参与。
    - **局限性：** 由于它只进行推理，因此该模型无法根据实时反馈调整其行为或与外部系统交互，这使得它在需要交互的任务中缺乏动态性。
2. **仅行动 (Act Only)**
    - 这种模型纯粹是为了在环境中行动而设计的。例子包括 WebGPT 和 SayCan 等系统，它们可以根据提示执行操作（例如，进行网络搜索和控制机器人）。
    - 在这里，语言模型在外部环境（Env）中行动，采取行动，并观察这些行动的结果。然而，它没有推理轨迹来逻辑地指导其行动；它更多地依赖于直接的行动-响应，而没有更深入的规划。
    - **局限性：** 没有推理，这种方法缺乏复杂、多步骤问题解决的能力。行动可能是反应性的，但缺乏可以提高长期有效性的战略思想。
3. **ReAct**
    - ReAct 框架在单个循环中结合了推理和行动。在这里，语言模型在环境中的推理轨迹和行动之间交替进行。
    - **过程：**
        - 模型首先推理任务，创建关于下一步应该做什么的“想法”或假设。
        - 然后，它根据其推理在环境中采取行动。
        - 执行操作后，模型观察环境中的结果，并将其纳入其下一个推理步骤。
        - 推理、行动和观察的循环持续迭代，使模型能够根据环境的实时反馈进行学习和适应。
    - **意义：** 通过整合推理和行动，ReAct 使模型能够将复杂、多步骤的任务分解为可管理的步骤，根据结果进行调整，并朝着需要规划和交互的解决方案努力。这种组合使 ReAct 非常适合动态、多步骤的任务，在这些任务中，模型必须不断适应和改进其方法。

**为什么 ReAct 强大？**


![image.png](/images/posts/AI-Agent的五种设计模式/image-5.png)


ReAct 框架回答了图表底部提出的问题：如果我们结合推理和行动会怎么样？


通过整合这两种能力，ReAct 使模型能够以协调的方式思考和行动。这增强了其能力：

- 解决复杂问题。
- 根据反馈调整行动。
- 在需要顺序决策的环境中有效运作。

本质上，ReAct 通过将内部推理与外部行动相结合，提供了一种更全面的任务完成方法，使其在纯粹推理或行动模型不足的实际应用中更加灵活和有效。


通过同时利用推理和行动，ReACT（Reason + Act）方法优于其他方法。这使得 AI 能够适应动态环境和复杂问题。该框架可以产生更复杂和准确的结果，非常适合需要思考和交互的任务。


[ReAct Agent 使用 LlamaIndex 和 Gemini 的实现文章链接]


**使用 OpenAI API 和 httpx 库的规划模式**


本节旨在概述构建利用 OpenAI API 和 httpx 库的 AI 智能体的过程。它介绍了创建能够处理用户输入并通过 OpenAI 的语言模型执行响应的聊天机器人类的基本结构。本节解释了如何实现 ReAct 模式，以实现思想、行动、暂停和观察的循环。它描述了注册自定义操作（例如，维基百科搜索、计算、博客搜索）以增强功能。这促进了动态交互，其中智能体可以使用外部操作来改进和完成其答案。让我们直接进入构建 AI 智能体的基本结构：


（此处省略代码，因为代码主要用于实现，在知识地图中已经体现了实现细节）


**使用 LangChain 和 ReAct 的规划模式**


目标是使用 LangChain 和 OpenAI 的 GPT 模型实现一个工具增强的 AI 智能体，该智能体可以通过集成 Tavily API 等自定义工具进行网络搜索，从而自主进行研究并回答复杂问题。该智能体旨在通过执行称为 ReAct（推理和行动）的规划模式来模拟类似人类的问题解决。它构建了一个推理和行动步骤的循环，评估响应，并做出决策以有效地收集和分析信息。该设置支持实时数据查询和结构化决策，从而增强对诸如“自金球奖设立以来，获奖者的名字是什么？”等问题的回答。


如果您想深入了解生成式 AI，请探索：[GenAI Pinnacle Program 链接]


## **ReWOO（Reasoning Without Observation）的工作流程**


ReWOO（Reasoning without Observation）是 Xu 等人提出的一种新的智能体架构，它强调在大型语言模型（LLM）系统中进行多步规划和变量替换的有效方法。它解决了 ReAct 式智能体架构中的一些局限性，特别是在执行效率和模型微调方面。以下是 ReWOO 如何改进传统方法的分解：


### **ReWOO 如何工作？**


![image.png](/images/posts/AI-Agent的五种设计模式/image-6.png)


这是 ReWOO（Reasoning Without Observation）智能体模型的工作流程。该模型旨在通过最小化冗余观察并专注于计划的行动序列来提高多步推理和工具使用的效率。以下是每个组件以及信息流的逐步说明：


### **ReWOO 的组件**

- **规划器（Planner）：**
    - 规划器负责在开始时创建整个计划。它确定解决任务所需的行动或步骤序列。
    - 对于每个行动步骤，规划器指定：
        - **工具：** 该步骤所需的特定工具或功能。
        - **参数（args）：** 工具所需的输入值或变量。
    - 该计划使用变量替换来定义，其中一个工具的输出（例如，#E1）可以用作另一个工具的参数（例如，#E2），从而在步骤之间创建依赖关系。
    - 重要的是，此规划过程在单个 LLM 调用中发生，通过减少 token 消耗使其比基于观察的迭代推理更有效。
- **工作器（Worker）：**
    - 工作器负责根据规划器生成的计划执行操作。
    - 工作器获取为每个步骤提供的参数，调用指定的工具，并返回结果。
    - 此执行可以循环进行，直到任务解决，确保每个工具操作都按照计划中概述的正确顺序完成。
    - 工作器独立于 LLM 运行，这意味着它只是遵循规划器的指令，而无需在每个步骤中额外调用 LLM。
- **求解器（Solver）：**
    - 求解器是解释工作器使用的工具结果的最终组件。
    - 根据从工具执行中收集的观察结果，求解器生成用户查询或任务的最终答案。
    - 此部分可能涉及最终的 LLM 调用，以将信息合成为连贯的响应。

### **ReWOO 的关键增强**


以下是 ReWOO 的关键增强：

- **高效的工具使用和减少的 token 消耗：**
    - **单次工具生成：** 与 ReAct 式智能体不同，后者需要对每个推理步骤进行多次 LLM 调用（因此每次调用都会重复整个系统提示和之前的步骤），ReWOO 在一次传递中生成所需工具的完整序列。
    - 这种方法大大减少了 token 消耗并缩短了执行时间，使其更适合涉及多个步骤或工具的复杂任务。
- **简化的微调过程：**
    - **将规划与工具输出解耦：** 由于 ReWOO 的规划数据不依赖于工具的实际输出，因此它允许更直接的微调过程。
    - **无需工具执行的微调：** 从理论上讲，可以在不调用任何工具的情况下对模型进行微调，因为它依赖于计划的操作和替换，而不是实际的工具响应。

### **工作流程**


该过程通过以下步骤进行：

1. **步骤 1 – 用户输入：**
    - 用户向 ReWOO 提交问题或任务。
    - 输入被传递给规划器以启动规划阶段。
2. **步骤 2 – 规划器创建计划：**
    - 规划器制定多步计划，指定要使用的工具和所需的参数。
    - 该计划可能涉及变量替换，其中一个工具的输出用作另一个工具的输入。
    - 然后，规划器将此完整计划提供给工作器。
3. **步骤 3 – 工作器执行操作：**
    - 工作器通过使用适当的参数调用指定的工具来执行计划的每个步骤。
    - 这个循环过程确保每个工具操作按顺序完成，直到任务完成。
4. **步骤 4 – 求解器生成答案：**
    - 执行完所有必要的操作后，求解器会解释结果并为用户生成最终答案。
    - 然后将此答案返回给用户，完成工作流程。

本质上，ReWOO 通过分离推理（规划器）和执行（工作器）阶段来提高智能体的效率，从而为复杂任务创建一个更快、更节省资源的框架。


### **有观察的推理和 ReWOO 的比较**


![image.png](/images/posts/AI-Agent的五种设计模式/image-7.png)


在涉及大型语言模型（LLM）的系统中，任务推理的两种不同方法是 (a) 有观察的推理和 (b) ReWOO（有观察和有组织证据的推理）。以下是基于给定图表的比较：

1. **依赖观察的推理（左侧面板）**
    - **设置和流程：**
        - 首先使用上下文和范例（示例或提示以帮助 LLM 的推理）增强用户的任务，然后将其输入到 LLM 以开始推理过程。
        - LLM 生成两个关键输出：
            - **T（Thought）：** 表示从 LLM 的初始处理中得出的内部思想或理解。
            - **A（Action）：** 这是 LLM 根据其思想决定采取的行动，通常涉及查询工具以获取信息。
        - 每次操作后，都会收到来自工具的观察结果（O）。此观察结果充当反馈循环，并附加到提示历史记录中，形成下一次 LLM 调用的更新输入。
    - **迭代性质：**
        - 此设置是迭代的，这意味着 LLM 会重复循环思考、行动和观察，直到获得足够的推理。
        - 每个循环都依赖于在提示历史记录中不断堆叠观察结果，随着时间的推移积累更多信息，从而产生提示冗余。
    - **局限性：**
        - 由于每次循环都会重复输入相同的上下文和范例，因此这种方法可能会导致提示冗余和潜在的低效率，因为相同的数据（上下文和范例）会反复反馈到系统中。
2. **ReWOO（右侧面板）**
    - **增强结构：**
        - 与依赖观察的推理设置不同，ReWOO 通过分离角色引入了一种更结构化的方法：
            - **规划器：** 负责创建一系列相互依赖的计划（P）。
            - **工作器：** 根据规划器的指示从各种工具中获取证据（E）。
        - 规划器生成计划，然后将其传递给工作器。工作器通过工具交互收集必要的证据来执行这些计划。
    - **计划和证据的作用：**
        - **计划（P）：** 这些是预定义的、相互依赖的步骤，概述了系统的推理路径。
        - **证据（E）：** 这是根据规划器的指示检索到的特定信息或数据。
        - 计划（P）和证据（E）的组合形成了一个更有组织的输入，它与原始任务和上下文一起，最终由求解器 LLM 处理以生成用户的输出。
    - **求解器：**
        - 求解器充当最终的推理模块，整合任务、上下文、计划和证据以生成连贯的答案。
        - 由于上下文和范例不会重复输入到 LLM 中，因此 ReWOO 减少了提示冗余的问题。

**ReWOO 的主要区别和优势**

- **提示效率：**
    - 依赖观察的推理会因重复循环相同的上下文和范例而遭受提示冗余，这可能会使提示过载并增加处理时间。
    - 另一方面，ReWOO 通过分离规划和证据收集阶段来避免这种冗余，使提示更有效率。
- **结构化任务执行：**
    - ReWOO 的设计引入了规划器和工作器，允许在任务规划和证据收集之间进行明确区分。这种结构化的流程确保每个步骤都按逻辑执行，从而更容易管理复杂的任务。
- **可扩展性：**
    - 凭借其模块化设置，ReWOO 可以有效地处理更复杂的任务。其结构化的规划和证据检索方法使其能够更好地扩展复杂的推理任务，因为每个组件（规划器、工作器、求解器）都有明确的角色。

**总结**

- **依赖观察的推理：** 循环思考、行动和观察，产生提示冗余但保持简单性。
- **ReWOO：** 通过使用规划器、工作器和求解器来简化推理、减少提示冗余并提高处理复杂任务的效率，从而使用更有组织的结构。

**ReWOO 的代码实现**


由于之前的示例已经涵盖了 OpenAI API + httpx 和 LangChain 的 ReAct 实现，对于 ReWOO，可以参考 Vadym Barda 的 ReWOO 方案，使用 LangGraph。此处强调的是，实现 ReWOO 的关键在于定义好状态图（StateGraph），包括规划器（Planner）、执行器（Executor）和求解器（Solver）的逻辑。


## **Agentic AI 规划模式的优点和局限性**


Agentic AI 规划模式提供了显着的优势，特别是当任务的复杂性阻止了预先确定的逐步分解时。 规划使智能体能够动态地决定其行动方案，从而实现自适应和上下文感知的问题解决。 它增强了处理不可预测任务的灵活性和能力，使其成为需要战略远见和决策的情况下的强大工具。


然而，这种能力伴随着明显的局限性。 规划的动态特性引入了不可预测性，使得更难预测智能体在任何给定场景中的行为方式。 与更具确定性的 Agentic 工作流（例如反思或工具使用）不同，规划仍然不太成熟，并且可能会产生不一致的结果。 虽然当前的规划能力提出了挑战，但 AI 研究的快速发展表明，这些局限性可能会随着时间的推移而减少，从而产生更强大和可预测的规划功能。


加入了二级和三级标题。 这应该使文章的结构更清晰，更易于阅读。


## AI 多智能体模式：协同智能的崛起

## **1. 什么是多智能体系统？**


多智能体系统是一个由多个自主智能体交互以协作或独立解决复杂问题的系统。每个智能体都可以专门处理任务、进行通信并协同工作。多智能体系统增强了模块化、可扩展性和控制性，使其适用于分布式系统、问题解决、模拟和基于 AI 的决策环境。


![image.png](/images/posts/AI-Agent的五种设计模式/image-8.png)


当出现以下情况时，单个基于智能体的 Agentic AI 系统可能会面临挑战：

- 需要处理的工具太多。
- 任务变得过于专业化而难以管理。
- 上下文状态开始变得过大。

多智能体系统拥有多个 AI 智能体，它们可以：

- 共同或独立工作。
- 解决更大的复杂问题。

多智能体系统的主要优点：

- **模块化：** 独立的智能体使得开发、测试和维护代理系统变得更容易。
- **专业化：** 专业智能体可以专注于特定领域，从而提高整体系统性能。
- **控制：** 对智能体如何通信进行显式控制。

## **2. Agentic AI 多智能体模式的架构**


![image.png](/images/posts/AI-Agent的五种设计模式/image-9.png)


该架构展示了一个 Agentic AI 多智能体系统，其中具有专门角色的各种智能体彼此交互，并与一个总体多智能体应用程序交互，以处理用户提示并生成响应。系统中的每个智能体都有独特的功能，模拟一个协作团队，共同高效地完成任务。


**组件说明：**

- **用户交互：**
    - **提示：** 用户通过向多智能体应用程序输入提示来启动交互。
    - **响应：** 系统通过协作智能体交互处理提示，并向用户返回响应。
- **智能体及其角色：**
    - **智能体 1：软件工程师：** 专注于与软件开发相关的技术问题解决，提供编码解决方案或建议基于软件的策略。
    - **智能体 2：项目经理：** 负责项目管理方面，协调智能体之间的工作，并确保流程与总体项目目标一致。
    - **智能体 3：内容开发人员：** 生成内容、撰写草稿或协助开发项目所需的文档和创意材料。
    - **智能体 4：市场调研分析师：** 收集数据、对市场趋势进行分析，并提供洞察以指导其他智能体的策略。
- **交互流程：**
    - 智能体之间的箭头表示通信通道和协作路径。这意味着：
        - **双向箭头（双头）：** 智能体可以来回交换信息，实现迭代协作。
        - **虚线：** 表示智能体之间的辅助或间接通信路径，表明在通信流程中扮演支持角色，而不是主要的协调角色。
- **通信工作流：**
    - **启动：** 用户向多智能体系统提供提示。
    - **协调：**
        - 智能体 1（软件工程师）可以首先确定任何初始技术要求或策略。
        - 智能体 2（项目经理）与智能体 1 和其他智能体协调，确保每个人都保持一致。
        - 智能体 3（内容开发人员）创建作为输出一部分可能需要的相关内容或草稿。
        - 智能体 4（市场调研分析师）提供研究数据，这些数据对于其他智能体做出明智的决策可能至关重要。
    - **完成：** 一旦所有智能体都进行了协作，系统就会编译最终响应并将其呈现给用户。

![image.png](/images/posts/AI-Agent的五种设计模式/image-10.png)


**关键特征：**

- **协作智能：** 该架构促进了协作式问题解决，具有专业知识的智能体贡献独特的见解和技能。
- **自主性：** 每个智能体都半独立地运作，专注于其特定角色，同时保持与其他智能体的通信。
- **可扩展性：** 可以通过添加更多专业智能体来扩展模型，以解决更复杂的用户提示。

该架构在需要多样化专业知识的多方面任务中特别有效，例如研究项目、产品开发和全面的内容创建。强调不同的角色和协调的沟通可确保复杂任务的每个部分都得到高效和紧密的处理。希望你已经了解了多智能体的工作原理。现在，我们将讨论一个构建多智能体解决方案的框架。


![image.png](/images/posts/AI-Agent的五种设计模式/image-11.png)

- **网络：** 每个智能体都可以与其他任何智能体通信。任何智能体都可以决定接下来调用哪个智能体。
- **主管：** 每个智能体都与一个主管智能体通信。主管智能体决定接下来应该调用哪个智能体。
- **主管（工具调用）：** 主管架构的特例。单个智能体可以表示为工具。主管智能体使用工具调用 LLM 来决定调用哪个智能体工具以及传递的参数。
- **分层：** 具有主管的主管的多智能体系统。这是主管架构的泛化，允许更复杂的控制流程。
- **自定义多智能体工作流：** 每个智能体仅与智能体的子集通信。部分流程是确定性的，只有一些智能体可以决定接下来调用哪个智能体。

**3. AutoGen：通过多智能体对话实现下一代 LLM 应用**


![image.png](/images/posts/AI-Agent的五种设计模式/image-12.png)


你知道许多框架（如 CrewAI、LangGraph 和 AutoGen）都为开发人员提供了构建多智能体解决方案的方法吗？今天，我们将讨论 AutoGen：


AutoGen 通过启用可定制和可对话的智能体（这些智能体设计用于在多智能体对话框架内运行）引入了 LLM 应用程序的新范式。这种设计植根于对现代 LLM 可以无缝地适应和整合反馈的理解，特别是那些针对对话进行了优化的 LLM（例如 GPT-4）。AutoGen 通过允许智能体进行对话交互来利用此功能——自主地或在人工监督下交换观察、评论和验证。


AutoGen 智能体的多功能性源于它们能够结合各种角色和行为，这些角色和行为可以根据开发人员的需求进行定制。例如，这些智能体可以被编程为编写或执行代码、整合人类反馈或验证结果。这种灵活性由开发人员可以轻松配置的模块化结构支持。每个智能体的后端都是可扩展的，允许进一步定制并增强其功能，使其超出默认设置。智能体的可对话性使它们能够保持持续的多轮对话并适应动态交互模式，使其适用于从问答和决策到复杂问题解决任务的各种应用。


**对话编程**


AutoGen 中的一项关键创新是对话编程的概念，它通过将开发过程简化为多智能体对话来革新 LLM 应用程序开发。这种编程范式将重点从传统的以代码为中心的工作流转移到以对话为中心的计算，使开发人员能够更直观地管理复杂的交互。对话编程分为两个核心步骤：

1. **定义可对话的智能体：** 开发人员通过配置内置功能来创建具有特定能力和角色的智能体。这些智能体可以设置为自主操作、与其他智能体协作，或在不同点涉及人类参与，从而确保自动化和用户控制之间的平衡。
2. **编程交互行为：** 开发人员通过以对话为中心的逻辑来编程这些智能体的交互方式。这涉及使用自然语言和代码的混合，从而实现对话模式的灵活脚本编写。AutoGen 借助可扩展或修改以用于实验或定制应用程序的即用型组件，促进了这些交互的无缝实现。

对话编程的集成支持不同 LLM 功能的模块化组合，从而能够将复杂任务划分为智能体可以协作解决的可管理子任务。该框架支撑了跨多个领域（包括研究、编码和互动娱乐）的强大且可扩展的 LLM 应用程序的开发。


**3.1 如何使用 AutoGen 编写多智能体对话？**


![image.png](/images/posts/AI-Agent的五种设计模式/image-13.png)


主要有三个部分：AutoGen 智能体、开发人员代码和程序执行，说明了如何使用 AutoGen 编写多智能体对话。下面是详细的分解：

1. **AutoGen 智能体**
    - **ConversableAgent：** 这是各种类型智能体运行的总体框架。该图突出显示了几种智能体类型：
        - **AssistantAgent：** 可配置选项，例如将 `human_input_mode` 设置为 "NEVER"，将 `code_execution_config` 设置为 `False`。这意味着智能体是完全自主的，并且在其操作期间不依赖于人工输入。
        - **UserProxyAgent：** 将 `human_input_mode` 设置为 "ALWAYS"，表明它是用户控制的，并且始终需要人工输入才能做出响应。
        - **GroupChatManager：** 管理群组对话中多个智能体之间的交互。
    - **统一对话接口：** 所有智能体共享用于发送、接收和生成回复的接口。
2. **开发人员代码**

    这部分演示了设置和自定义智能体之间交互的步骤。

    - **定义智能体：**
        - 定义了两个智能体，用户代理 A 和助手 B。它们可以相互通信，构成多智能体对话的基础。
    - **注册自定义回复函数：**
        - 为一个智能体（智能体 B）注册了一个自定义回复函数 (reply_func_A2B)。此函数概述了智能体 B 在被调用时如何生成回复。
        - 该函数包含一个简单的逻辑结构：

            ```python
            def reply_func_A2B(msg):
                output = input_from_human()
                if not output:
                    if msg includes code:
                        output = execute(msg)
                return output
            ```

        - 此函数允许智能体 B 从人类获取输入或执行代码（如果输入消息包含可执行命令）。
    - **启动对话：** 显示了一个示例启动行：
        - `initiate_chat("Plot a chart of META and TESLA stock price change YTD.”)`
        - 这行代码设置智能体 A 启动与智能体 B 的对话，要求它根据给定的命令绘制图表。
3. **程序执行**

    这部分详细介绍了初始化后对话如何进行。

    - **对话驱动的控制流：**
        - 交互从智能体 A 向智能体 B 发送请求开始。
        - 然后，智能体 B 接收请求并调用 `generate_reply` 函数，如果需要，该函数可能会触发代码执行。
    - **以对话为中心的计算：**
        - 流程显示了消息如何在 `generate_reply` 和智能体之间传递：
            - 例如，在尝试执行命令后，如果缺少所需的包，则会发回一条错误消息（例如，“Error: package yfinance is not installed”）。
            - 然后，回复会通知用户安装缺少的包（“Sorry! Please first pip install yfinance and then execute”）。

简而言之，它可视化了如何使用 AutoGen 编写智能体之间的对话驱动交互。该过程包括定义智能体、通过回复函数自定义其行为以及处理对话控制流，包括执行代码和响应用户请求。


AutoGen 智能体、开发人员代码和程序执行旨在指导开发人员设置自动化的多智能体交互，从定义和自定义智能体到观察对话和执行的控制流。


## **4. Agentic AI 多智能体模式实战**


![image.png](/images/posts/AI-Agent的五种设计模式/image-14.png)


在这里，我们将讨论 Agentic AI 多智能体对话（这受到了 [Deeplearning.ai](http://deeplearning.ai/) 的启发）。我使用的是 AutoGen，它有一个内置的智能体类，称为“Conversable agent”。


让我们从设置开始。


```python
!pip install openai
# python==3.10.13
!pip install pyautogen==0.2.25
import os
os.environ['OPENAI_API_KEY']='你的API密钥'
llm_config = {"model": "gpt-4o"}
```


该配置指定了要使用的模型 (gpt-4o)。


**定义 AutoGen 智能体**


`ConversableAgent` 类创建一个聊天机器人智能体。`human_input_mode="NEVER"` 表示智能体在对话期间不会请求人工用户输入。


```python
from autogen import ConversableAgent
agent = ConversableAgent(
   name="chatbot",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
reply = agent.generate_reply(
   messages=[{"content": "你是一位著名的人工智能专家。现在给我讲两个关于人工智能的笑话。", "role": "user"}]
)
print(reply)

#输出 (示例)
# 好的，这里有两个关于人工智能的笑话：
# 1. 为什么人工智能害怕蜘蛛？因为它有太多 bug！
# 2. 为什么人工智能不擅长讲笑话？因为它的算法太严肃了！

reply = agent.generate_reply(
   messages=[{"content": "重复这个笑话。", "role": "user"}]
)
print(reply)

# 输出 (示例)
# 当然！请告诉我你想让我重复哪个笑话？
```


**设置对话**


设置两个智能体 Sunil 和 Harshit 之间的对话，其中保留了他们互动的记忆。


Harshit 和 Sunil 是 AI 驱动的智能体，专为参与社交媒体报告的幽默对话而设计。Harshit 是一位社交媒体专家和办公室喜剧演员，他使用轻松幽默的语言来保持对话的活跃性。Sunil 作为内容部门负责人和 Harshit 的上级，也具有这种喜剧特质，通过从上一个笑话的妙语开始下一个笑话来增加结构化幽默。这两个智能体都使用预配置的 LLM 设置并自主操作 (`human_input_mode=”NEVER”`)。这种动态模拟了工作场所的玩笑，将专业讨论与娱乐相结合，非常适合培训、团队模拟或内容生成。持续的喜剧流程模仿了真实的办公室互动，增强了参与度和相关性。


`ConversableAgent` 通常是一个人工智能智能体，能够根据预定义的系统消息和配置参与对话。这些智能体使用大型语言模型 (LLM) 提供的自然语言处理 (NLP) 功能来根据其系统消息指令进行智能响应。


```python
Harshit = ConversableAgent(
   name="Harshit",
   system_message=
   "你的名字是 Harshit，你是一位社交媒体专家，并在办公室做单口喜剧。"
   "这也是一场办公室喜剧"
   "这次对话是关于社交媒体报告的"
   "保持语言轻松幽默",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
Sunil = ConversableAgent(
   name="Sunil",
   system_message=
   "你的名字是 Sunil，你是 Analytics Vidhya 内容部门的负责人，Harshit 是你的下属，你也在办公室做单口喜剧。"
   "从上一个笑话的妙语开始下一个笑话。"
   "这也是一场办公室喜剧，Harshit 是 Sunil 的下属"
   "这必须有趣且不那么冗长"
    "这次对话是关于社交媒体报告的",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
```


两个智能体 Harshit 和 Sunil 由其独特的属性、个性和背景定义。根据他们的角色，他们被指示进行幽默的互动。


```python
chat_result = Sunil.initiate_chat(
   recipient=Harshit,
   message="我是 Sunil。Harshit，让我们继续讲笑话。",
   max_turns=3,
)
```


Sunil 使用初始消息和 3 个对话回合的限制开始与 Harshit 对话。


```python
import pprint
pprint.pprint(chat_result.chat_history)
#输出示例 (对话内容可能有所不同, 但结构类似)
```


**关于对话终止**


此代码是定义聊天机器人智能体 Harshit 和 Sunil（他们扮演单口喜剧演员）的设置的一部分。目标是自定义他们的行为，特别是他们如何处理对话终止。通过指定终止消息，机器人可以自然地结束他们的交互，遵循预定义的提示，如“我得走了”。


这有助于：

- **增强用户体验：** 用户获得更直观和类似人类的交互，并以清晰且相关的方式结束对话。
- **保持流程和幽默：** 由于这些智能体是单口喜剧演员，因此使用有趣的短语管理他们的退出台词符合他们的角色并增强了沉浸感。

```python
Harshit = ConversableAgent(
   name="Harshit",
   system_message=
   "你的名字是 Harshit，你是一位单口喜剧演员。"
   "当你准备结束对话时，说'我得走了'。",
   llm_config=llm_config,
   human_input_mode="NEVER",
   is_termination_msg=lambda msg: "我得走了" in msg["content"],
)
Sunil = ConversableAgent(
   name="Sunil",
   system_message=
   "你的名字是 Sunil，你是一位单口喜剧演员。"
   "当你准备结束对话时，说'我得走了'。",
   llm_config=llm_config,
   human_input_mode="NEVER",
   is_termination_msg=lambda msg: "我得走了" in msg["content"] or "再见" in msg["content"],
)
chat_result = joe.initiate_chat( # 应该是 Sunil.initiate_chat
   recipient=cathy, # 应该是 Harshit
   message="我是 Sunil。Harshit，让我们继续讲笑话。"
)
# 输出示例 (对话内容可能有所不同, 但结构类似, 并且会以 "我得走了" 结束)
```


**输出分析**


Sunil 和 Harshit 之间的对话展现了一种轻松幽默的交流，保持了他们定义的角色（例如，社交媒体专业知识和办公室喜剧）。


聊天记录记录了智能体之间的来回消息，展示了他们如何根据彼此的内容进行构建、响应提示并保持连贯的流程。


**关键点**

- **智能体定制：** 每个智能体都有一个定义的名称、角色和系统消息，从而实现定制的交互。
- **笑话链接：** Sunil 的系统消息确保每个笑话都建立在前一个妙语的基础上。
- **终止处理：** 两个智能体都可以识别表示对话结束的短语。
- **幽默和轻松的语言：** 该系统旨在创建一种引人入胜且诙谐的交流，强调幽默和相关性。

此设置可用于创建自动化的、基于角色的对话模拟，适用于各种应用，例如互动讲故事、聊天机器人或培训模拟。


让我们看看如何从头开始构建一个多智能体系统。


**4.1 从零开始构建 Agentic AI 多智能体模式**


首先，感谢 Michaelis Trofficus 通过展示如何从头开始构建所有 Agentic 设计模式来简化生活。在上面的部分中，我使用了 AutoGen 框架，但现在，让我们看看如何从头开始构建它。


注意：Michaelis 借鉴了 Airflow 的设计方法，使用“>>”和“<<”符号来指示智能体之间的依赖关系。在这个简化的微型 CrewAI 模型中，智能体就像 Airflow 任务一样工作，而 Crew 就像 Airflow DAG 一样工作。


此外，他一直在研究 CrewAI 的极简版本，并从两个关键概念中汲取灵感：Crew 和 Agent。


通过研究极简版本，Michaelis 的目标可能是创建一个更简单、更精简的 CrewAI 框架，专注于基本功能并避免复杂的、无关紧要的元素。这将使系统更易于使用和调整，同时保留受 Crew（团队协调）和 Agent（个体自主性）模型启发的关键协作和任务委派功能。在深入实践之前，让我们了解一下这些：


**什么是 Crew？**


GitHub Crew: [https://github.com/joaomdmoura/crewAI](https://github.com/joaomdmoura/crewAI)


`Crew` 类旨在表示一组在协调环境中协同工作的智能体。它提供了一个以结构化方式管理和执行智能体的框架，确保尊重它们之间的依赖关系。

1. **Crew 的核心概念**
    - `Crew` 类充当智能体集合的管理者，提供了在上下文中将它们作为一个内聚单元进行处理的方法。
    - 该结构确保智能体按照尊重其依赖关系的顺序运行，从而防止冲突并实现顺利执行。
2. **Crew 类中的关键属性和方法**
    - `current_crew`（类属性）：跟踪当前活动的 `Crew` 实例。这对于在创建或注册智能体时将它们与正确的 `Crew` 上下文相关联至关重要。
    - `__init__` 方法：初始化 `Crew` 实例并创建一个空列表 `agents` 来存储属于该 crew 的智能体。
    - 上下文管理器方法（`__enter__` 和 `__exit__`）：
        - `__enter__`：当在 `with` 语句中使用 `Crew` 实例时，此方法将其设置为活动 crew。
        - `__exit__`：退出 `with` 块时清除活动 crew 上下文。
    - `add_agent` 方法：将新智能体添加到 `agents` 列表。
    - `register_agent`（静态方法）：如果 `current_crew` 不为 `None`，则通过将智能体添加到 `agents` 列表来将其与活动 `Crew` 相关联。
    - `topological_sort` 方法：
        - 目的：根据智能体的依赖关系按拓扑顺序对它们进行排序，以防止任何循环引用。
        - 过程：
            - 使用 `in-degree` 字典跟踪每个智能体的依赖关系。
            - 将没有依赖关系的智能体添加到队列中并处理它们以构建排序列表。
            - 如果检测到循环依赖关系（当排序列表与智能体总数不匹配时），则会引发错误。
    - `plot` 方法：使用 Graphviz 将智能体及其依赖关系可视化为有向无环图 (DAG)。
    - `run` 方法：
        - 功能：按 `topological_sort` 确定的顺序运行所有智能体。
        - 执行：调用每个智能体的 `run` 方法并使用 `fancy_print` 以获得更好的输出格式。
3. **工作原理**
    - **上下文管理：** `Crew` 类使用上下文管理（`__enter__` 和 `__exit__`）来创建一个范围，其中所有智能体都与特定的 crew 相关联。这使得在定义的上下文中管理智能体的生命周期和交互变得更容易。
    - **拓扑排序：** 拓扑排序确保智能体按照解决依赖关系的顺序执行。这在智能体依赖于彼此的输出或状态的场景中至关重要。
    - **图形可视化：** `plot` 方法提供了依赖结构清晰的视觉表示，有助于理解执行流程。

`Crew` 类是一个用于管理相互依赖的智能体的综合解决方案，它通过拓扑排序、可视化和执行机制提供上下文管理和依赖关系解析——所有这些对于涉及协调的基于智能体的操作的工作流都是必不可少的。


**什么是 Agent？**


在此代码上下文中，`Agent` 是一个抽象，表示能够在多智能体系统中协作以完成任务的 AI 单元。该设计结合了用于智能体间依赖关系管理、任务执行和智能体之间上下文共享的功能。`Agent` 类的关键组件是：

- **属性：**
    - 名称、背景故事、任务描述和任务预期输出：这些定义了智能体的身份和特定任务细节。
    - `ReactAgent`：用于生成响应的内置实例，表明 `Agent` 基于反应式 AI 架构。
    - 依赖项和依赖者：列出当前智能体依赖或负责的其他智能体。
    - 上下文：一个累积从其他智能体共享的上下文或结果的字符串属性，用于影响其输出。
- **初始化（****`__init__`** **方法）：**
    - 设置智能体的核心属性并将智能体注册到会话（在此上下文中称为“Crew”）（如果存在）。
    - 将智能体与工具和特定语言模型（默认为“llama-3.1-70b-versatile”）相关联。
- **依赖关系管理：**
    - 智能体使用自定义运算符（`>>` 和 `<<`）来直观地表达和建立智能体之间的依赖关系，灵感来自 Apache Airflow 等数据管道框架。
    - `add_dependency` 和 `add_dependent` 方法以编程方式处理智能体关系的管理。
- **功能：**
    - `receive_context`：接收来自依赖智能体的输出并将其添加到上下文，这丰富了智能体的任务执行。
    - `create_prompt`：根据智能体的任务、上下文和预期输出构建一个全面的提示，以指导响应生成。
    - `run`：通过使用生成的提示执行任务，运行 `ReactAgent`，然后将结果传播给所有依赖者。
- **协作机制：**
    - 智能体形成一个能够协作工作、共享上下文和输出的多智能体系统，其中每个智能体都可以根据依赖关系触发后续智能体。
    - `Crew` 抽象充当协调系统来注册和管理这些智能体，形成一个面向任务的实体网络。

总的来说，`Agent` 本质上是一个模块化的、自给自足的 AI 单元，可以与其他智能体协调和通信，以协作解决复杂任务。它充当更广泛的 AI 驱动工作流中的一个节点，能够自主处理任务并为多智能体系统的集体输出做出贡献。


**什么是 Tool？**


`Tool` 是一个充当函数包装器的类，它捕获有关函数签名的详细信息，并提供执行该函数的方法。从本质上讲，`Tool` 对象使更统一地管理函数成为可能，包括验证输入参数和呈现有关函数的元数据。


**工作原理**

- **创建工具：** 可以使用 `@tool` 装饰器来包装任何函数。这将创建一个 `Tool` 实例，其中包含有关函数的元数据并提供运行它的方法。
- **执行工具：** `Tool` 对象上的 `run` 方法允许使用关键字参数执行包装的函数。
- **输入验证：** `validate_arguments` 函数有助于确保输入的类型正确，使 `Tool` 的执行更可靠和可预测。

**开始吧！**


作者构建了他自己的 `Agent`、`Crew` 和 `tool` 的自定义实现，正如我们之前详细讨论的那样，因为将相关功能和行为封装在专用类和模块中非常有用且模块化。现在，我们将导入这些类和函数，并使用它们从头开始构建我们的多智能体系统。


**实现**


完整代码请参考此仓库：[multiagent_pattern](https://github.com/michaelistrofficus/agentic_patterns/tree/main) (链接有效)


```python
from agentic_patterns.multiagent_pattern.agent import Agent
from agentic_patterns.tool_pattern.tool import tool
from agentic_patterns.multiagent_pattern.crew import Crew

# Agent：用于创建具有特定角色和任务的智能体实例的类。
# tool：将函数公开为智能体可以使用的工具的装饰器。
# Crew：管理多个智能体并控制它们执行任务的顺序。

# 将函数定义为智能体可以使用的工具
@tool
def write_str_to_txt(string_data: str, txt_filename: str):
    """
    将字符串写入 txt 文件。

    此函数获取一个字符串并将其写入文本文件。如果文件已存在，
    它将被新数据覆盖。

    Args:
        string_data (str): 包含要写入文件的数据的字符串。
        txt_filename (str): 应将数据写入的文本文件的名称。
    """
    # 将字符串数据写入文件
    with open(txt_filename, mode='w', encoding='utf-8') as file:
        file.write(string_data)

    print(f'数据已成功写入 {txt_filename}')

# @tool 装饰器：将 write_str_to_txt 标记为智能体可以使用的工具。
# 函数用途：获取一个字符串并将其写入指定的文本文件。如果文件存在，它将被覆盖。
# 参数：
#     string_data：要写入文件的内容。
#     txt_filename：输出文件的名称。

# 创建一组智能体来执行一系列任务
with Crew() as crew:
    # 定义第一个智能体：写诗的诗人
    agent_1 = Agent(
        name="Poet Agent",
        backstory="你是一位著名的诗人，喜欢创作高质量的诗歌。",
        task_description="写一首关于生命意义的诗",
        task_expected_output="只输出诗歌，没有任何标题或介绍性句子",
    )

    # 定义第二个智能体：西班牙语翻译
    agent_2 = Agent(
        name="Poem Translator Agent",
        backstory="你是一位专业的翻译，尤其擅长西班牙语",
        task_description="将一首诗翻译成西班牙语",
        task_expected_output="只输出翻译后的诗歌，不包含其他任何内容",
    )

    # 定义第三个智能体：将内容保存到文本文件的编写者
    agent_3 = Agent(
        name="Writer Agent",
        backstory="你是一位专业的转录员，喜欢将诗歌写入 txt 文件",
        task_description="你将在上下文中收到一首西班牙语诗歌。你需要将诗歌写入 './poem.txt' 文件。",
        task_expected_output="一个包含从上下文中收到的西班牙语诗歌的 txt 文件",
        tools=write_str_to_txt,  # 允许此智能体使用前面定义的工具
    )

    # 定义智能体的工作流程顺序
    agent_1 >> agent_2 >> agent_3

# 运行智能体组，按指定的顺序执行他们的任务
    crew.run()

# with Crew() as crew:: 启动一个用于定义和运行智能体的上下文。
# agent_1：
#     Name: “Poet Agent”
#     Backstory: 将其定位为熟练的诗人。
#     Task Description: 撰写一首关于生命意义的诗歌。
#     Expected Output: 仅输出诗歌，不包含其他文本。
# agent_2：
#     Name: “Poem Translator Agent”
#     Backstory: 将其确立为西班牙语专家。
#     Task Description: 将一首诗翻译成西班牙语。
#     Expected Output: 仅翻译后的诗歌。
# agent_3：
#     Name: “Writer Agent”
#     Backstory: 将其描述为转录专家。
#     Task Description: 将西班牙语诗歌写入名为 ./poem.txt 的文本文件。
#     Tools: 可以访问 write_str_to_txt 工具以保存诗歌。
# Workflow (agent_1 >> agent_2 >> agent_3):
#     建立智能体完成其任务的顺序：首先，由 agent_1 创建诗歌，然后由 agent_2 翻译，最后由 agent_3 保存到文件。
# crew.run(): 触发按指定顺序执行任务。

# 这是 crew 的图示
crew.plot()
```


(Plot Graph 图片,  显示了 Agent 1 -> Agent 2 -> Agent 3 的流程)


完整代码：notebooks/multiagent\_pattern.ipynb  (在提供的 GitHub 仓库中)


## **5. MetaGPT 智能体：基于标准操作流程的多智能体元编程**


![image.png](/images/posts/AI-Agent的五种设计模式/image-15.png)


MetaGPT 是一个使用大型语言模型 (LLM) 进行多智能体协作的框架，旨在通过标准操作流程 (SOP) 复制类似人类的工作流程。这种方法通过构建 LLM 交互来减少逻辑不一致和幻觉，从而增强问题解决能力。MetaGPT 分解复杂任务、分配专门角色，并通过定义的输出确保质量。它在代码生成基准测试中优于 AutoGPT 和 LangChain 等现有系统，展示了一种用于软件工程的强大且高效的元编程解决方案。


**结构化方法和 SOP 驱动的工作流程**


MetaGPT 通过结合模仿标准操作程序 (SOP) 的结构化方法，代表了元编程的一项突破。这个基于 GPT 模型的创新框架要求智能体生成详细且结构化的输出，例如需求文档、设计工件和技术规范。这些输出确保了沟通的清晰度并最大限度地减少了协作期间的错误，从而有效地提高了生成代码的准确性和一致性。MetaGPT 中的 SOP 驱动工作流组织智能体以协同工作，类似于软件


**角色区分和任务管理**


通过定义产品经理、架构师、工程师、项目经理和质量保证工程师等专门角色，MetaGPT 将复杂的任务编排成可管理的特定操作。这种角色区分有助于项目的有效执行，每个智能体都贡献其专业知识并保持结构化沟通。整合这些实践可以实现更无缝和有效的协作过程，限制可能阻碍进度的冗余消息或错误沟通等问题。


**通信协议和反馈系统**


MetaGPT 还具有创新的通信协议，允许智能体通过结构化接口和发布-订阅机制交换有针对性的信息并访问共享资源。一个独特的功能是可执行的反馈系统，它不仅检查而且在运行时改进和运行代码，从而显着提高生成输出的质量和可靠性。


**以人为本的实践的应用**


SOP 等以人为本的实践的应用增强了系统的稳健性，使其成为构建基于 LLM 的多智能体架构的强大工具。这种在协作框架内对元编程的开创性使用为人工智能体之间更规范和类似人类的交互铺平了道路，将 MetaGPT 定位为多智能体系统设计领域的前瞻性方法。


**5.1 MetaGPT 中的软件开发流程**


![image.png](/images/posts/AI-Agent的五种设计模式/image-16.png)


提供的图表说明了 MetaGPT（一种基于 GPT 的元编程框架）如何通过实施标准操作程序 (SOP) 来管理软件开发过程。以下是图表的细分：

1. **用户输入：** 该过程从用户提供项目需求开始，在本例中是创建一个 2048 滑动数字益智游戏。
2. **产品经理 (PM)：**
    - 产品经理进行彻底的分析并制定详细的产品需求文档 (PRD)。
    - PRD 包括产品目标、用户故事、竞争分析和需求分析。
    - 此分析将用户需求分解为可管理的部分，并定义项目的主要目标、用户需求和设计注意事项。
3. **架构师：**
    - 架构师接收 PRD 并将其转换为系统设计。
    - 此设计包括程序调用流程、文件列表以及构建软件组件的高级计划。
    - 架构师确定组件将如何交互以及将使用哪些工具和框架（例如，使用 Python 进行游戏开发的 Pygame）。
4. **项目经理 (PM)：**
    - 项目经理然后根据架构师的系统设计创建任务列表，并将工作分配给相应的智能体。
    - 这确保了任务被明确定义并与项目需求保持一致。
5. **工程师：**
    - 工程师根据详细计划致力于实现指定的代码和功能。
    - 显示的代码片段突出显示了核心游戏逻辑的开发，其中包括 2048 游戏所需的类和函数。
6. **质量保证工程师：**
    - 质量保证工程师审查并测试代码以进行质量保证。
    - 此步骤确保游戏满足预定义的要求并保持功能和可靠性的高标准。
7. **最终产品：**
    - 该图包含最终输出的视觉表示，显示用户如何与开发的游戏进行交互。

如图所示的工作流程强调了信息和任务从一个角色到另一个角色的顺序流动，展示了 MetaGPT 如何使用定义的 SOP 来简化开发过程。这种结构化方法通过在智能体之间实施明确的角色、职责和标准通信实践，最大限度地减少了错误沟通并最大限度地提高了生产力。


**5.2 为什么多智能体系统需要 MetaGPT？**


基于大型语言模型 (LLM) 的多智能体系统在处理复杂任务时面临重大挑战。虽然它们可以有效地执行简单的对话任务，但由于逻辑一致性的固有局限性，更复杂的场景会出现问题。这些问题通常会因级联幻觉而加剧，其中错误会随着 LLM 被简单地链接在一起而复合，从而导致有缺陷或不正确的结果。


MetaGPT 通过以下几个关键创新解决了这些挑战：

- **元编程框架：** MetaGPT 提供了一种独特的元编程方法，将结构化的类似人类的工作流程集成到多智能体交互中。这种结构化框架确保智能体遵循系统化的方法，类似于人类在解决复杂问题时使用的方法。
- **标准化操作程序 (SOP)：** 通过将 SOP 编码到提示序列中，MetaGPT 将多智能体系统的工作流程与定义明确的程序对齐。这导致智能体之间更顺畅的协作并最大限度地减少逻辑不一致，因为这些 SOP 指导智能体完成结构化过程。
- **通过验证减少错误：** MetaGPT 框架内的智能体被设计为模拟类似人类的领域专业知识，使他们能够验证中间结果并检查其输出的正确性。此验证步骤对于减少可能由典型基于 LLM 的系统故障引起的错误至关重要。
- **流水线范式：** MetaGPT 引入了一种类似于流水线的任务管理方法，其中各种智能体被分配特定的角色。这种结构化的角色分配确保复杂任务被分解为可管理的子任务，促进多个智能体之间的协调努力并提高整体任务执行。
- **在基准测试中提高性能：** 在涉及协作软件工程基准测试的测试中，MetaGPT 已显示出与传统的基于聊天的多智能体系统相比，能够产生更连贯和可靠的输出。这证明了其流水线结构和特定于角色的任务划分在实现更好的任务结果方面的有效性。

多智能体系统需要 MetaGPT 通过结构化的、类似人类的工作流程来管理复杂任务的复杂性，从而减少错误和逻辑不一致。通过采用 SOP、角色分配和中间结果验证，MetaGPT 确保智能体协作高效地工作，从而实现卓越的性能和连贯的任务完成。


## **6. Agentic AI 多智能体模式的优点**


![image.png](/images/posts/AI-Agent的五种设计模式/image-17.png)


以下是多智能体模式的优点：

- **通过协作提高性能：** 与单个智能体相比，部署多个 AI 智能体一起工作通常会产生更好的结果。智能体之间的协作努力可以带来更好的结果，研究表明多智能体设置中的性能更好就证明了这一点。
- **提高注意力和理解力：** 能够处理大量输入的语言模型 (LLM) 可能仍然难以理解复杂或冗长的信息。通过为不同的智能体分配特定角色，每个智能体都可以专注于特定任务，从而增强整体理解力和效率。
- **优化子任务以提高效率：** 将复杂的项目分解为更小、可管理的子任务允许每个智能体专门化并优化其分配的角色。这种有针对性的方法可确保任务的每个组成部分都得到更精确和高效的处理。
- **复杂任务的结构化框架：** 多智能体模式提供了一种系统化的方法来分解复杂的任务，类似于开发人员在编程中使用进程或线程的方式。这种结构简化了复杂项目的管理和执行。
- **熟悉的管理类比：** 管理 AI 智能体反映了经理在组织中监督团队的方式。这种熟悉的概念有助于开发人员直观地为智能体分配角色和职责，利用对团队动态的现有理解。
- **灵活和动态的工作流程：** 每个智能体都使用自己的工作流程和内存系统进行操作，从而实现与其他智能体的动态交互和协作。这种灵活性使智能体能够参与规划、工具使用并适应不断变化的需求，从而实现高效和复杂的工作流程。
- **降低实验风险：** 管理不善的人力团队可能会产生重大后果，但尝试使用 AI 智能体的风险要小得多。这允许在优化智能体角色和交互方面进行试错，而不会产生严重影响。
- **高效的资源利用：** 将特定任务分配给专用智能体可确保有效地使用计算资源。这种有针对性的分配可防止单个智能体过载并促进平衡的工作负载分配。
- **可扩展性和适应性：** 多智能体方法允许通过根据需要添加或调整智能体来轻松扩展任务。这种适应性对于处理不同规模和复杂性的项目至关重要。
- **增强的问题解决能力：** 智能体之间的协作交互可以带来创新的解决方案并改进问题解决。多个智能体的综合专业知识和观点可以发现单个智能体可能遗漏的方法。
- **改进的任务优先级：** 通过指定每个智能体子任务的重要性，开发人员可以确保项目的关键方面得到适当的关注。这种优先级排序提高了每个智能体输出的质量和相关性。

Agentic AI 多智能体模式提供了一个强大的框架，用于提高复杂任务的性能、效率和可扩展性。通过模拟熟悉的管理结构并利用专业智能体的优势，这种方法增强了 AI 系统的功能，同时最大限度地降低了与管理不善相关的风险。


此外，要更好地了解 Agentic AI，请探索：Agentic AI 先锋计划。(原文中有一个课程链接，这里省略)


## **7. 结论**


Agentic AI 多智能体模式是 AI 设计中的一种高级架构，体现了一种协作框架，其中专门的智能体协同工作以完成复杂的任务。在反思、工具使用和规划等基础模式的基础上，Agentic AI 多智能体模式将大型项目划分为可管理的子任务，允许具有独特角色的智能体贡献其专业知识。这种模块化方法促进了协调的问题解决、自主性和可扩展性，促进了类似于现实世界管理中团队动态的高效工作流程。


多智能体模式的优点包括增强的注意力、优化的任务执行、动态适应性和改进的问题解决能力。通过模拟人类团队管理和培养智能体自主性，这种模式为跨各个行业（从软件工程到内容创建等）更复杂、可靠和高效的 AI 应用铺平了道路。

